# -*- coding: utf-8 -*-

"""
Script para analizar im√°genes en lote (batch) usando la API de Visi√≥n de OpenAI.

Este script realiza los siguientes pasos:
1.  Define y crea la estructura de carpetas necesaria.
2.  Carga un prompt de sistema desde un archivo externo.
3.  Lee un archivo CSV que contiene las URLs p√∫blicas de las im√°genes a analizar.
4.  Genera una tarea para cada imagen, asignando un ID √∫nico.
5.  Crea un archivo de batch en memoria (sin guardarlo en disco).
6.  Pide confirmaci√≥n al usuario antes de enviar el lote para controlar costos.
7.  Sube el archivo en memoria y crea el trabajo de batch en OpenAI.
"""

# --- Parte 1: Configuraci√≥n e Inicializaci√≥n ---
import json
import io
import pandas as pd
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# Carga variables de entorno desde un archivo .env en la ra√≠z del proyecto
load_dotenv()

# --- Configuraci√≥n de Rutas del Proyecto ---
# El script est√° en 'src/inference/', as√≠ que subimos DOS niveles para llegar a la ra√≠z.
PROJECT_ROOT = Path(__file__).resolve().parent.parent

# Ruta al archivo que contiene el prompt del sistema.
PROMPT_FILE_PATH = PROJECT_ROOT / 'prompts' / 'caption_system_prompt.txt'

# Ruta al archivo CSV limpio que contiene las URLs de las im√°genes.
INPUT_CSV_PATH = PROJECT_ROOT / 'data' / 'clean' / 'delitos_imagenes_santiago_limpio.csv'

# Carpeta de salida para los resultados que la API de OpenAI generar√°.
# Este script no crea archivos aqu√≠, pero es una buena pr√°ctica tenerla definida.
BATCH_OUTPUT_FOLDER_PATH = PROJECT_ROOT / 'data' / 'inferences'

# --- Creaci√≥n de Carpetas ---
# Asegura que las carpetas necesarias existan.
BATCH_OUTPUT_FOLDER_PATH.mkdir(parents=True, exist_ok=True)
(PROJECT_ROOT / 'prompts').mkdir(parents=True, exist_ok=True)

# --- Funciones Auxiliares ---
def load_prompt_from_file(file_path: Path) -> str:
    """Carga y devuelve el contenido de un archivo de texto."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"‚ùå Error CR√çTICO: El archivo de prompt '{file_path}' no se encontr√≥.")
        raise
    except Exception as e:
        print(f"‚ùå Error CR√çTICO al leer el archivo de prompt '{file_path}': {e}")
        raise

# --- Inicializaci√≥n del Cliente y Carga del Prompt ---
try:
    client = OpenAI()
    print("‚úÖ Cliente de OpenAI inicializado correctamente.")
except Exception as e:
    print(f"‚ùå Error CR√çTICO al inicializar el cliente de OpenAI: {e}")
    raise

SYSTEM_PROMPT = load_prompt_from_file(PROMPT_FILE_PATH)
print("‚úÖ Prompt del sistema cargado.")


# --- Parte 2: Carga de Datos y Generaci√≥n de Tareas ---
print("\nIniciando la generaci√≥n de tareas para el batch de im√°genes...")

try:
    df = pd.read_csv(INPUT_CSV_PATH)
    print(f"‚úÖ Se cargaron {len(df)} registros desde '{INPUT_CSV_PATH.name}'.")
except FileNotFoundError:
    print(f"‚ùå Error CR√çTICO: No se encontr√≥ el archivo de entrada en '{INPUT_CSV_PATH}'.")
    raise
except Exception as e:
    print(f"‚ùå Error CR√çTICO al leer el archivo CSV: {e}")
    raise

batch_tasks_list = []
for index, row in df.iterrows():
    # Asumimos que el CSV tiene columnas 'nombre_foto' y 'public_url'
    image_id = row.get('nombre_foto', f'task-{index}') # Usa 'nombre_foto' si existe, si no un gen√©rico
    image_url = row.get('public_url')

    if not image_url:
        print(f"‚ö†Ô∏è Advertencia: Fila {index} no tiene 'public_url'. Saltando.")
        continue

    # Crea el cuerpo de la petici√≥n para cada imagen
    task_item = {
        "custom_id": str(image_id),
        "method": "POST",
        "url": "/v1/chat/completions",
        "body": {
            "model": "gpt-4o-mini", # Modelo optimizado y m√°s econ√≥mico
            "temperature": 0.2,
            "max_tokens": 500, # Ajusta seg√∫n la longitud de respuesta esperada
            "response_format": {"type": "json_object"}, # Recomendado si esperas un JSON
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Analiza la siguiente imagen de una calle y describe los elementos relevantes seg√∫n tus instrucciones."},
                        {"type": "image_url", "image_url": {"url": image_url, "detail": "low"}} # detail: low para ahorrar tokens
                    ],
                }
            ]
        }
    }
    batch_tasks_list.append(task_item)

print(f"‚úÖ Generaci√≥n de tareas completada. Total de tareas: {len(batch_tasks_list)}")

# --- Parte 3: Creaci√≥n y Env√≠o del Archivo Batch ---
if not batch_tasks_list:
    print("No se generaron tareas. Finalizando el proceso.")
else:
    # Confirmaci√≥n del usuario para evitar costos inesperados
    user_confirmation = input(f"Se han generado {len(batch_tasks_list)} tareas. ¬øDeseas enviar el batch a OpenAI? (s/N): ")

    if user_confirmation.lower() != 's':
        print("Env√≠o cancelado por el usuario.")
    else:
        print("\n‚öôÔ∏è  Procediendo con la creaci√≥n y env√≠o del batch...")

        try:
            # Crear el archivo JSONL en memoria para no guardarlo en disco
            batch_stream = io.BytesIO()
            for task in batch_tasks_list:
                batch_stream.write((json.dumps(task) + '\n').encode('utf-8'))
            batch_stream.seek(0) # Regresar al inicio del stream para que la API lo lea

            # 1. Subir el archivo en memoria a OpenAI
            print("Subiendo archivo batch a OpenAI...")
            batch_file = client.files.create(
                file=("batch_input.jsonl", batch_stream), # Pasamos el stream como un archivo
                purpose="batch"
            )
            print(f"‚úÖ Archivo subido con ID: {batch_file.id}")

            # 2. Crear el trabajo de batch
            print("Creando el job de batch en OpenAI...")
            batch_job = client.batches.create(
                input_file_id=batch_file.id,
                endpoint="/v1/chat/completions",
                completion_window="24h"
            )
            print(f"üöÄ ¬°√âxito! Job de batch enviado con ID: {batch_job.id}")
            print("Puedes monitorear el estado en tu dashboard de OpenAI o con otro script.")

        except Exception as e:
            print(f"‚ùå Error CR√çTICO durante el env√≠o del batch a OpenAI: {e}")